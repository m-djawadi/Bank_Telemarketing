{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3kPS2_g34eW",
        "outputId": "bf43d277-0cda-4d5d-f567-21c0fc3c34ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import copy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Activation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTpyVerS4A8X",
        "outputId": "d2eacbe4-40ed-4465-8b7f-03045fb906b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNb6a38e4Bp7"
      },
      "source": [
        "data=pd.read_csv('gdrive/My Drive/bank-additional-full.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2GxbE3u4Bn9",
        "outputId": "f0111b09-992d-49f5-ef37-882047c7db84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>housemaid</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.4y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>307</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age        job  marital  ... euribor3m nr.employed   y\n",
              "0   56  housemaid  married  ...     4.857      5191.0  no\n",
              "1   57   services  married  ...     4.857      5191.0  no\n",
              "2   37   services  married  ...     4.857      5191.0  no\n",
              "3   40     admin.  married  ...     4.857      5191.0  no\n",
              "4   56   services  married  ...     4.857      5191.0  no\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS1j4w1la9OX"
      },
      "source": [
        "this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ju8QU-katqy",
        "outputId": "85b9c520-f39d-4cf3-b9c7-ee0c096343e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "data.drop(['duration'], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>housemaid</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.4y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>basic.6y</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>high.school</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>telephone</td>\n",
              "      <td>may</td>\n",
              "      <td>mon</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>1.1</td>\n",
              "      <td>93.994</td>\n",
              "      <td>-36.4</td>\n",
              "      <td>4.857</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41183</th>\n",
              "      <td>73</td>\n",
              "      <td>retired</td>\n",
              "      <td>married</td>\n",
              "      <td>professional.course</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>nov</td>\n",
              "      <td>fri</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>94.767</td>\n",
              "      <td>-50.8</td>\n",
              "      <td>1.028</td>\n",
              "      <td>4963.6</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41184</th>\n",
              "      <td>46</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>professional.course</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>nov</td>\n",
              "      <td>fri</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>94.767</td>\n",
              "      <td>-50.8</td>\n",
              "      <td>1.028</td>\n",
              "      <td>4963.6</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41185</th>\n",
              "      <td>56</td>\n",
              "      <td>retired</td>\n",
              "      <td>married</td>\n",
              "      <td>university.degree</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>nov</td>\n",
              "      <td>fri</td>\n",
              "      <td>2</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>94.767</td>\n",
              "      <td>-50.8</td>\n",
              "      <td>1.028</td>\n",
              "      <td>4963.6</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41186</th>\n",
              "      <td>44</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>professional.course</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>nov</td>\n",
              "      <td>fri</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "      <td>0</td>\n",
              "      <td>nonexistent</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>94.767</td>\n",
              "      <td>-50.8</td>\n",
              "      <td>1.028</td>\n",
              "      <td>4963.6</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41187</th>\n",
              "      <td>74</td>\n",
              "      <td>retired</td>\n",
              "      <td>married</td>\n",
              "      <td>professional.course</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>nov</td>\n",
              "      <td>fri</td>\n",
              "      <td>3</td>\n",
              "      <td>999</td>\n",
              "      <td>1</td>\n",
              "      <td>failure</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>94.767</td>\n",
              "      <td>-50.8</td>\n",
              "      <td>1.028</td>\n",
              "      <td>4963.6</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41188 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age          job  marital  ... euribor3m nr.employed    y\n",
              "0       56    housemaid  married  ...     4.857      5191.0   no\n",
              "1       57     services  married  ...     4.857      5191.0   no\n",
              "2       37     services  married  ...     4.857      5191.0   no\n",
              "3       40       admin.  married  ...     4.857      5191.0   no\n",
              "4       56     services  married  ...     4.857      5191.0   no\n",
              "...    ...          ...      ...  ...       ...         ...  ...\n",
              "41183   73      retired  married  ...     1.028      4963.6  yes\n",
              "41184   46  blue-collar  married  ...     1.028      4963.6   no\n",
              "41185   56      retired  married  ...     1.028      4963.6   no\n",
              "41186   44   technician  married  ...     1.028      4963.6  yes\n",
              "41187   74      retired  married  ...     1.028      4963.6   no\n",
              "\n",
              "[41188 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahh9wL-Z62ox",
        "outputId": "b21377fe-939c-478c-c44b-95cc94f49c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "data_encoded = data.apply(le.fit_transform)\n",
        "print(data_encoded) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       age  job  marital  education  ...  cons.conf.idx  euribor3m  nr.employed  y\n",
            "0       39    3        1          0  ...             16        287            8  0\n",
            "1       40    7        1          3  ...             16        287            8  0\n",
            "2       20    7        1          3  ...             16        287            8  0\n",
            "3       23    0        1          1  ...             16        287            8  0\n",
            "4       39    7        1          3  ...             16        287            8  0\n",
            "...    ...  ...      ...        ...  ...            ...        ...          ... ..\n",
            "41183   56    5        1          5  ...              0        171            0  1\n",
            "41184   29    1        1          5  ...              0        171            0  0\n",
            "41185   39    5        1          6  ...              0        171            0  0\n",
            "41186   27    9        1          5  ...              0        171            0  1\n",
            "41187   57    5        1          5  ...              0        171            0  0\n",
            "\n",
            "[41188 rows x 21 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4vEZ_xO68L2",
        "outputId": "2a2593bd-e52e-49bf-eef2-006e48032fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "data_encoded.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>261</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>226</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  job  marital  education  ...  cons.conf.idx  euribor3m  nr.employed  y\n",
              "0   39    3        1          0  ...             16        287            8  0\n",
              "1   40    7        1          3  ...             16        287            8  0\n",
              "2   20    7        1          3  ...             16        287            8  0\n",
              "3   23    0        1          1  ...             16        287            8  0\n",
              "4   39    7        1          3  ...             16        287            8  0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxr6wTpJ4Bk9",
        "outputId": "437a997a-94c2-43be-93c9-14875f5cd071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "char_cols = data.dtypes.pipe(lambda x: x[x == 'object']).index\n",
        "\n",
        "for c in char_cols:\n",
        "    data[c] = pd.factorize(data[c])[0]\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nchar_cols = data.dtypes.pipe(lambda x: x[x == 'object']).index\\n\\nfor c in char_cols:\\n    data[c] = pd.factorize(data[c])[0]\\n    \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7zPvF5C4BhT",
        "outputId": "b06eb67a-1ce3-4d61-b083-fadd0be4d2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "char_cols = data.dtypes.pipe(lambda x: x[x == 'object']).index\n",
        "label_mapping = {}\n",
        "\n",
        "for c in char_cols:\n",
        "    data[c], label_mapping[c] = pd.factorize(data[c])\n",
        "\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nchar_cols = data.dtypes.pipe(lambda x: x[x == 'object']).index\\nlabel_mapping = {}\\n\\nfor c in char_cols:\\n    data[c], label_mapping[c] = pd.factorize(data[c])\\n\\n  \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh-JdbhJ4JvJ"
      },
      "source": [
        "X = data_encoded.drop('y', axis=1)\n",
        "Y = data_encoded['y']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqTurLlRjkoj",
        "outputId": "9b58eeb5-5e2a-4181-bf45-52f8c82dfad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>month</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>emp.var.rate</th>\n",
              "      <th>cons.price.idx</th>\n",
              "      <th>cons.conf.idx</th>\n",
              "      <th>euribor3m</th>\n",
              "      <th>nr.employed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>261</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>226</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>287</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  job  marital  ...  cons.conf.idx  euribor3m  nr.employed\n",
              "0   39    3        1  ...             16        287            8\n",
              "1   40    7        1  ...             16        287            8\n",
              "2   20    7        1  ...             16        287            8\n",
              "3   23    0        1  ...             16        287            8\n",
              "4   39    7        1  ...             16        287            8\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY1jvBNgjmd7",
        "outputId": "6bf2ef2d-a5aa-4a96-f04e-4cf1e11e3ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "Y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo-UIGXY4JyA"
      },
      "source": [
        "df=np.array(X) \n",
        "target=np.array(Y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UQZJ9ib4J06"
      },
      "source": [
        "####We can define these data as a matrix of 20 columns with 41188 rows:\n",
        "#data = data.reshape(1, 41188, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gssGrWzh4J30",
        "outputId": "7e35624e-a0a2-4177-878b-99ccd627158e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41188, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhfPhZOV4J7h",
        "outputId": "53bfeecf-f6cb-40c7-b507-3f7c76f2fb30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41188,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6r2fiGP4Tmj"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df,target, test_size=0.2, random_state=10)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.25, random_state=56)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT1bgzfd4Trb",
        "outputId": "46c1d551-4718-4aa3-d6be-32fb8462c163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print('x_train = ', x_train.shape, '\\ny_train = ', y_train.shape)\n",
        "print('x_test = ', x_test.shape, '\\ny_test = ', y_test.shape)\n",
        "print('x_valid = ', x_valid.shape, '\\ny_valid = ', y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train =  (24712, 20) \n",
            "y_train =  (24712,)\n",
            "x_test =  (8238, 20) \n",
            "y_test =  (8238,)\n",
            "x_valid =  (8238, 20) \n",
            "y_valid =  (8238,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1P_2Tcx4TvJ",
        "outputId": "4c06f668-4bdc-47f2-c361-d68b7ece60f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24712, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jeh6vU614Tpm",
        "outputId": "12174e79-acab-4667-afda-721c97b273b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], 1)\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24712, 20, 1)\n",
            "(8238, 20, 1)\n",
            "(8238, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJajv7DK4TkQ"
      },
      "source": [
        "#x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "#x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "#x_valid = np.reshape(x_valid,(x_valid.shape[0], 1, x_valid.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmGtsX9V4eZs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVPF-L3V57_D",
        "outputId": "f4a0ea08-7786-4ec8-9291-ad7eb6c143e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.contrib.keras.api.keras import layers\n",
        "from tensorflow.contrib.keras.api.keras.layers import Dense, LSTM, Bidirectional, Flatten\n",
        "from tensorflow.keras.layers import LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras import optimizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4a55679b7797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6QTgiezYnoM"
      },
      "source": [
        "model_new = Sequential()\n",
        "model_new.add(Bidirectional(LSTM(100, return_sequences=True), batch_input_shape=(None,11,48), merge_mode='ave'))\n",
        "model_new.add(BatchNormalization())\n",
        "model_new.add(Bidirectional(LSTM(100, return_sequences=True), batch_input_shape=(None,11,48), merge_mode='ave'))\n",
        "model_new.add(BatchNormalization())\n",
        "model_new.add(Flatten())\n",
        "model_new.add(Dense(100, activation='sigmoid'))\n",
        "model_new.add(BatchNormalization())\n",
        "model_new.add(Dense(32, activation='sigmoid'))\n",
        "model_new.add(BatchNormalization())\n",
        "model_new.add(Dense(2, activation='softmax'))\n",
        "\n",
        "adam=tf.keras.optimizers.Adam( learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "model_new.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_new.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxGA03NN4eUX",
        "outputId": "d271b242-7c1d-4592-f4f8-36faf2ca4297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 10,451\n",
            "Trainable params: 10,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlyFdYeq4Thl",
        "outputId": "3649c1cb-157a-47a3-8236-88834fc41456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Checkpoint = ModelCheckpoint( 'hist',monitor='acc', \n",
        "                           verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "history=model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=100, callbacks=[Checkpoint], batch_size=256, verbose=1, shuffle=True)\n",
        "# model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=10, batch_size=2048, verbose=1, shuffle=True)\n",
        "# model.save('m.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 24712 samples, validate on 8238 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "24712/24712 [==============================] - 5s 203us/step - loss: 0.1338 - acc: 0.8455 - val_loss: 0.0888 - val_acc: 0.8825\n",
            "\n",
            "Epoch 00001: acc improved from -inf to 0.84554, saving model to hist\n",
            "Epoch 2/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0827 - acc: 0.8922 - val_loss: 0.0869 - val_acc: 0.8832\n",
            "\n",
            "Epoch 00002: acc improved from 0.84554 to 0.89220, saving model to hist\n",
            "Epoch 3/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0791 - acc: 0.8972 - val_loss: 0.0735 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00003: acc improved from 0.89220 to 0.89722, saving model to hist\n",
            "Epoch 4/100\n",
            "24712/24712 [==============================] - 4s 142us/step - loss: 0.0662 - acc: 0.9058 - val_loss: 0.0657 - val_acc: 0.9028\n",
            "\n",
            "Epoch 00004: acc improved from 0.89722 to 0.90584, saving model to hist\n",
            "Epoch 5/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0635 - acc: 0.9076 - val_loss: 0.0638 - val_acc: 0.9053\n",
            "\n",
            "Epoch 00005: acc improved from 0.90584 to 0.90762, saving model to hist\n",
            "Epoch 6/100\n",
            "24712/24712 [==============================] - 4s 144us/step - loss: 0.0626 - acc: 0.9092 - val_loss: 0.0634 - val_acc: 0.9069\n",
            "\n",
            "Epoch 00006: acc improved from 0.90762 to 0.90919, saving model to hist\n",
            "Epoch 7/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0634 - acc: 0.9081 - val_loss: 0.0624 - val_acc: 0.9058\n",
            "\n",
            "Epoch 00007: acc did not improve from 0.90919\n",
            "Epoch 8/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0619 - acc: 0.9092 - val_loss: 0.0628 - val_acc: 0.9064\n",
            "\n",
            "Epoch 00008: acc did not improve from 0.90919\n",
            "Epoch 9/100\n",
            "24712/24712 [==============================] - 4s 144us/step - loss: 0.0608 - acc: 0.9095 - val_loss: 0.0618 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00009: acc improved from 0.90919 to 0.90952, saving model to hist\n",
            "Epoch 10/100\n",
            "24712/24712 [==============================] - 4s 150us/step - loss: 0.0616 - acc: 0.9102 - val_loss: 0.0618 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00010: acc improved from 0.90952 to 0.91021, saving model to hist\n",
            "Epoch 11/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0610 - acc: 0.9127 - val_loss: 0.0619 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00011: acc improved from 0.91021 to 0.91267, saving model to hist\n",
            "Epoch 12/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0608 - acc: 0.9124 - val_loss: 0.0615 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00012: acc did not improve from 0.91267\n",
            "Epoch 13/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0601 - acc: 0.9134 - val_loss: 0.0618 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00013: acc improved from 0.91267 to 0.91340, saving model to hist\n",
            "Epoch 14/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0601 - acc: 0.9128 - val_loss: 0.0610 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00014: acc did not improve from 0.91340\n",
            "Epoch 15/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0600 - acc: 0.9149 - val_loss: 0.0606 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00015: acc improved from 0.91340 to 0.91490, saving model to hist\n",
            "Epoch 16/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0597 - acc: 0.9148 - val_loss: 0.0617 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00016: acc did not improve from 0.91490\n",
            "Epoch 17/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0598 - acc: 0.9144 - val_loss: 0.0634 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00017: acc did not improve from 0.91490\n",
            "Epoch 18/100\n",
            "24712/24712 [==============================] - 4s 150us/step - loss: 0.0598 - acc: 0.9144 - val_loss: 0.0628 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00018: acc did not improve from 0.91490\n",
            "Epoch 19/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0598 - acc: 0.9139 - val_loss: 0.0611 - val_acc: 0.9092\n",
            "\n",
            "Epoch 00019: acc did not improve from 0.91490\n",
            "Epoch 20/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0593 - acc: 0.9128 - val_loss: 0.0605 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00020: acc did not improve from 0.91490\n",
            "Epoch 21/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0599 - acc: 0.9130 - val_loss: 0.0611 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00021: acc did not improve from 0.91490\n",
            "Epoch 22/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0593 - acc: 0.9146 - val_loss: 0.0639 - val_acc: 0.9085\n",
            "\n",
            "Epoch 00022: acc did not improve from 0.91490\n",
            "Epoch 23/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0595 - acc: 0.9145 - val_loss: 0.0611 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00023: acc did not improve from 0.91490\n",
            "Epoch 24/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0593 - acc: 0.9141 - val_loss: 0.0609 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00024: acc did not improve from 0.91490\n",
            "Epoch 25/100\n",
            "24712/24712 [==============================] - 4s 150us/step - loss: 0.0593 - acc: 0.9138 - val_loss: 0.0606 - val_acc: 0.9084\n",
            "\n",
            "Epoch 00025: acc did not improve from 0.91490\n",
            "Epoch 26/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0591 - acc: 0.9140 - val_loss: 0.0602 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00026: acc did not improve from 0.91490\n",
            "Epoch 27/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0592 - acc: 0.9145 - val_loss: 0.0609 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00027: acc did not improve from 0.91490\n",
            "Epoch 28/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0586 - acc: 0.9154 - val_loss: 0.0605 - val_acc: 0.9088\n",
            "\n",
            "Epoch 00028: acc improved from 0.91490 to 0.91539, saving model to hist\n",
            "Epoch 29/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0587 - acc: 0.9153 - val_loss: 0.0601 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00029: acc did not improve from 0.91539\n",
            "Epoch 30/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0590 - acc: 0.9147 - val_loss: 0.0604 - val_acc: 0.9118\n",
            "\n",
            "Epoch 00030: acc did not improve from 0.91539\n",
            "Epoch 31/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0585 - acc: 0.9146 - val_loss: 0.0607 - val_acc: 0.9088\n",
            "\n",
            "Epoch 00031: acc did not improve from 0.91539\n",
            "Epoch 32/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0584 - acc: 0.9140 - val_loss: 0.0602 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00032: acc did not improve from 0.91539\n",
            "Epoch 33/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0590 - acc: 0.9150 - val_loss: 0.0600 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00033: acc did not improve from 0.91539\n",
            "Epoch 34/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0585 - acc: 0.9155 - val_loss: 0.0605 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00034: acc improved from 0.91539 to 0.91547, saving model to hist\n",
            "Epoch 35/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0586 - acc: 0.9151 - val_loss: 0.0598 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00035: acc did not improve from 0.91547\n",
            "Epoch 36/100\n",
            "24712/24712 [==============================] - 4s 150us/step - loss: 0.0585 - acc: 0.9155 - val_loss: 0.0617 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00036: acc improved from 0.91547 to 0.91551, saving model to hist\n",
            "Epoch 37/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0584 - acc: 0.9157 - val_loss: 0.0604 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00037: acc improved from 0.91551 to 0.91575, saving model to hist\n",
            "Epoch 38/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0585 - acc: 0.9147 - val_loss: 0.0605 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00038: acc did not improve from 0.91575\n",
            "Epoch 39/100\n",
            "24712/24712 [==============================] - 4s 150us/step - loss: 0.0580 - acc: 0.9153 - val_loss: 0.0602 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00039: acc did not improve from 0.91575\n",
            "Epoch 40/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0580 - acc: 0.9144 - val_loss: 0.0597 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00040: acc did not improve from 0.91575\n",
            "Epoch 41/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0581 - acc: 0.9152 - val_loss: 0.0604 - val_acc: 0.9088\n",
            "\n",
            "Epoch 00041: acc did not improve from 0.91575\n",
            "Epoch 42/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0578 - acc: 0.9154 - val_loss: 0.0604 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00042: acc did not improve from 0.91575\n",
            "Epoch 43/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0577 - acc: 0.9149 - val_loss: 0.0606 - val_acc: 0.9077\n",
            "\n",
            "Epoch 00043: acc did not improve from 0.91575\n",
            "Epoch 44/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0579 - acc: 0.9150 - val_loss: 0.0603 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00044: acc did not improve from 0.91575\n",
            "Epoch 45/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0573 - acc: 0.9163 - val_loss: 0.0595 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00045: acc improved from 0.91575 to 0.91632, saving model to hist\n",
            "Epoch 46/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0572 - acc: 0.9161 - val_loss: 0.0616 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00046: acc did not improve from 0.91632\n",
            "Epoch 47/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0569 - acc: 0.9157 - val_loss: 0.0594 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00047: acc did not improve from 0.91632\n",
            "Epoch 48/100\n",
            "24712/24712 [==============================] - 4s 152us/step - loss: 0.0570 - acc: 0.9161 - val_loss: 0.0602 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00048: acc did not improve from 0.91632\n",
            "Epoch 49/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0565 - acc: 0.9153 - val_loss: 0.0599 - val_acc: 0.9096\n",
            "\n",
            "Epoch 00049: acc did not improve from 0.91632\n",
            "Epoch 50/100\n",
            "24712/24712 [==============================] - 4s 150us/step - loss: 0.0568 - acc: 0.9153 - val_loss: 0.0612 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00050: acc did not improve from 0.91632\n",
            "Epoch 51/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0570 - acc: 0.9160 - val_loss: 0.0599 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00051: acc did not improve from 0.91632\n",
            "Epoch 52/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0573 - acc: 0.9165 - val_loss: 0.0632 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00052: acc improved from 0.91632 to 0.91648, saving model to hist\n",
            "Epoch 53/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0567 - acc: 0.9170 - val_loss: 0.0596 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00053: acc improved from 0.91648 to 0.91696, saving model to hist\n",
            "Epoch 54/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0564 - acc: 0.9166 - val_loss: 0.0600 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00054: acc did not improve from 0.91696\n",
            "Epoch 55/100\n",
            "24712/24712 [==============================] - 4s 150us/step - loss: 0.0566 - acc: 0.9176 - val_loss: 0.0610 - val_acc: 0.9084\n",
            "\n",
            "Epoch 00055: acc improved from 0.91696 to 0.91761, saving model to hist\n",
            "Epoch 56/100\n",
            "24712/24712 [==============================] - 4s 155us/step - loss: 0.0560 - acc: 0.9173 - val_loss: 0.0599 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00056: acc did not improve from 0.91761\n",
            "Epoch 57/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0563 - acc: 0.9184 - val_loss: 0.0599 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00057: acc improved from 0.91761 to 0.91838, saving model to hist\n",
            "Epoch 58/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0564 - acc: 0.9174 - val_loss: 0.0600 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00058: acc did not improve from 0.91838\n",
            "Epoch 59/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0563 - acc: 0.9166 - val_loss: 0.0595 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00059: acc did not improve from 0.91838\n",
            "Epoch 60/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0557 - acc: 0.9172 - val_loss: 0.0594 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00060: acc did not improve from 0.91838\n",
            "Epoch 61/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0560 - acc: 0.9170 - val_loss: 0.0597 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00061: acc did not improve from 0.91838\n",
            "Epoch 62/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0562 - acc: 0.9173 - val_loss: 0.0639 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00062: acc did not improve from 0.91838\n",
            "Epoch 63/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0562 - acc: 0.9171 - val_loss: 0.0593 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00063: acc did not improve from 0.91838\n",
            "Epoch 64/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0555 - acc: 0.9183 - val_loss: 0.0603 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00064: acc did not improve from 0.91838\n",
            "Epoch 65/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0556 - acc: 0.9182 - val_loss: 0.0592 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00065: acc did not improve from 0.91838\n",
            "Epoch 66/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0556 - acc: 0.9196 - val_loss: 0.0631 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00066: acc improved from 0.91838 to 0.91955, saving model to hist\n",
            "Epoch 67/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0562 - acc: 0.9167 - val_loss: 0.0595 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00067: acc did not improve from 0.91955\n",
            "Epoch 68/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0554 - acc: 0.9184 - val_loss: 0.0592 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00068: acc did not improve from 0.91955\n",
            "Epoch 69/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0559 - acc: 0.9179 - val_loss: 0.0592 - val_acc: 0.9097\n",
            "\n",
            "Epoch 00069: acc did not improve from 0.91955\n",
            "Epoch 70/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0558 - acc: 0.9177 - val_loss: 0.0590 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00070: acc did not improve from 0.91955\n",
            "Epoch 71/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0554 - acc: 0.9180 - val_loss: 0.0618 - val_acc: 0.9082\n",
            "\n",
            "Epoch 00071: acc did not improve from 0.91955\n",
            "Epoch 72/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0558 - acc: 0.9179 - val_loss: 0.0598 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00072: acc did not improve from 0.91955\n",
            "Epoch 73/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0553 - acc: 0.9179 - val_loss: 0.0592 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00073: acc did not improve from 0.91955\n",
            "Epoch 74/100\n",
            "24712/24712 [==============================] - 4s 143us/step - loss: 0.0556 - acc: 0.9181 - val_loss: 0.0605 - val_acc: 0.9099\n",
            "\n",
            "Epoch 00074: acc did not improve from 0.91955\n",
            "Epoch 75/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0556 - acc: 0.9186 - val_loss: 0.0607 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00075: acc did not improve from 0.91955\n",
            "Epoch 76/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0551 - acc: 0.9192 - val_loss: 0.0592 - val_acc: 0.9124\n",
            "\n",
            "Epoch 00076: acc did not improve from 0.91955\n",
            "Epoch 77/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0549 - acc: 0.9198 - val_loss: 0.0596 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00077: acc improved from 0.91955 to 0.91984, saving model to hist\n",
            "Epoch 78/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0549 - acc: 0.9191 - val_loss: 0.0594 - val_acc: 0.9136\n",
            "\n",
            "Epoch 00078: acc did not improve from 0.91984\n",
            "Epoch 79/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0546 - acc: 0.9191 - val_loss: 0.0591 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00079: acc did not improve from 0.91984\n",
            "Epoch 80/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0547 - acc: 0.9195 - val_loss: 0.0610 - val_acc: 0.9122\n",
            "\n",
            "Epoch 00080: acc did not improve from 0.91984\n",
            "Epoch 81/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0555 - acc: 0.9186 - val_loss: 0.0592 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00081: acc did not improve from 0.91984\n",
            "Epoch 82/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0553 - acc: 0.9195 - val_loss: 0.0602 - val_acc: 0.9115\n",
            "\n",
            "Epoch 00082: acc did not improve from 0.91984\n",
            "Epoch 83/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0550 - acc: 0.9203 - val_loss: 0.0602 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00083: acc improved from 0.91984 to 0.92028, saving model to hist\n",
            "Epoch 84/100\n",
            "24712/24712 [==============================] - 4s 143us/step - loss: 0.0546 - acc: 0.9191 - val_loss: 0.0592 - val_acc: 0.9113\n",
            "\n",
            "Epoch 00084: acc did not improve from 0.92028\n",
            "Epoch 85/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0548 - acc: 0.9202 - val_loss: 0.0599 - val_acc: 0.9109\n",
            "\n",
            "Epoch 00085: acc did not improve from 0.92028\n",
            "Epoch 86/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0548 - acc: 0.9197 - val_loss: 0.0622 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00086: acc did not improve from 0.92028\n",
            "Epoch 87/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0554 - acc: 0.9194 - val_loss: 0.0597 - val_acc: 0.9102\n",
            "\n",
            "Epoch 00087: acc did not improve from 0.92028\n",
            "Epoch 88/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0545 - acc: 0.9199 - val_loss: 0.0617 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00088: acc did not improve from 0.92028\n",
            "Epoch 89/100\n",
            "24712/24712 [==============================] - 4s 143us/step - loss: 0.0546 - acc: 0.9207 - val_loss: 0.0626 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00089: acc improved from 0.92028 to 0.92069, saving model to hist\n",
            "Epoch 90/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0550 - acc: 0.9198 - val_loss: 0.0635 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00090: acc did not improve from 0.92069\n",
            "Epoch 91/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0548 - acc: 0.9196 - val_loss: 0.0590 - val_acc: 0.9104\n",
            "\n",
            "Epoch 00091: acc did not improve from 0.92069\n",
            "Epoch 92/100\n",
            "24712/24712 [==============================] - 4s 142us/step - loss: 0.0542 - acc: 0.9209 - val_loss: 0.0590 - val_acc: 0.9119\n",
            "\n",
            "Epoch 00092: acc improved from 0.92069 to 0.92089, saving model to hist\n",
            "Epoch 93/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0540 - acc: 0.9208 - val_loss: 0.0603 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00093: acc did not improve from 0.92089\n",
            "Epoch 94/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0540 - acc: 0.9215 - val_loss: 0.0602 - val_acc: 0.9116\n",
            "\n",
            "Epoch 00094: acc improved from 0.92089 to 0.92146, saving model to hist\n",
            "Epoch 95/100\n",
            "24712/24712 [==============================] - 4s 145us/step - loss: 0.0541 - acc: 0.9218 - val_loss: 0.0590 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00095: acc improved from 0.92146 to 0.92178, saving model to hist\n",
            "Epoch 96/100\n",
            "24712/24712 [==============================] - 4s 150us/step - loss: 0.0545 - acc: 0.9205 - val_loss: 0.0612 - val_acc: 0.9103\n",
            "\n",
            "Epoch 00096: acc did not improve from 0.92178\n",
            "Epoch 97/100\n",
            "24712/24712 [==============================] - 4s 149us/step - loss: 0.0538 - acc: 0.9215 - val_loss: 0.0593 - val_acc: 0.9133\n",
            "\n",
            "Epoch 00097: acc did not improve from 0.92178\n",
            "Epoch 98/100\n",
            "24712/24712 [==============================] - 4s 148us/step - loss: 0.0541 - acc: 0.9209 - val_loss: 0.0597 - val_acc: 0.9093\n",
            "\n",
            "Epoch 00098: acc did not improve from 0.92178\n",
            "Epoch 99/100\n",
            "24712/24712 [==============================] - 4s 147us/step - loss: 0.0538 - acc: 0.9226 - val_loss: 0.0602 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00099: acc improved from 0.92178 to 0.92259, saving model to hist\n",
            "Epoch 100/100\n",
            "24712/24712 [==============================] - 4s 146us/step - loss: 0.0540 - acc: 0.9207 - val_loss: 0.0618 - val_acc: 0.9079\n",
            "\n",
            "Epoch 00100: acc did not improve from 0.92259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzGpXE8P9rzA"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('hist') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83mNh170-TtR",
        "outputId": "af037929-6ac5-4a00-c7a5-ff91ea38b610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDM-oEMR_zIQ"
      },
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7TgzdUY-Ndb"
      },
      "source": [
        "# make predictions\n",
        "\n",
        "y_pred = model.predict(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvRia2VjHAsh",
        "outputId": "43953f63-2bc2-48fb-e2e9-44eed6eb9cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (y_train.shape , y_pred.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24712,) (24712, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoLoKhPSq5Uo"
      },
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "transformer = Binarizer().fit(y_pred)  # fit does nothing.\n",
        "transformer\n",
        "y_pred=transformer.transform(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m7FIXpFuR14"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc9RNbBYIz1b",
        "outputId": "bd8acc3e-a695-4968-88ac-ac18d913955f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sklearn.metrics as metrics \n",
        "from sklearn.metrics import accuracy_score\n",
        "# Print the prediction accuracy\n",
        "print (metrics.accuracy_score(y_train, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5937601165425704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ugO5MazA26T",
        "outputId": "00a79f15-3554-4deb-b0d9-0421e29f63e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(classification_report(y_train, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.54      0.70     21959\n",
            "           1       0.21      0.99      0.35      2753\n",
            "\n",
            "    accuracy                           0.59     24712\n",
            "   macro avg       0.61      0.77      0.53     24712\n",
            "weighted avg       0.91      0.59      0.66     24712\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVrlmbWiJkE3"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX126SjxJmqZ",
        "outputId": "e40fafbb-2b71-440f-f78a-e14f124a6b98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(x_test)\n",
        "preds = probs \n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:248: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
            "  warnings.warn('Network returning invalid probability values. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUYiISFL/D7nFo+YAX8g1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZmVe8nCp5GV"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}